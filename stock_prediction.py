from keras.layers.core import Dense, Activation, Dropout
from keras.layers.recurrent import LSTM
from keras.models import Sequential
import pandas as pd
pd.core.common.is_list_like = pd.api.types.is_list_like
from pandas_datareader import data
import matplotlib.pyplot as plt
import datetime as dt
import urllib.request, json
import os
import numpy as np
from sklearn import preprocessing
from helper_methods import load_data, build_model
import math

# alpha vantage api key
api_key = '6BXJN99BEYM5VWU3'

# Amazon stock market prices
ticker = "MSFT"

# JSON file with all the stock market data for AMZN from the last 20 years
url_string = "https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=%s&outputsize=full&apikey=%s"%(ticker,api_key)

# Save data to this file
file_to_save = 'Stock CSV Files/stock_market_data-%s.csv'%ticker

# Saved data,
# Grab the data from the url
# And store date, low, high, volume, close, open, adj close values to a Pandas DataFrame
if not os.path.exists(file_to_save):
    with urllib.request.urlopen(url_string) as url:
        data = json.loads(url.read().decode())
        # extract stock market data
        data = data['Time Series (Daily)']
        df = pd.DataFrame(columns=['Date','Low','High','Close','Open','Volume', 'Adj Close'])
        for k,v in data.items():
            date = dt.datetime.strptime(k, '%Y-%m-%d')
            data_row = [date.date(),float(v['3. low']),float(v['2. high']),
                        float(v['4. close']),float(v['1. open']),float(v['6. volume']),float(v['5. adjusted close'])]
            df.loc[-1,:] = data_row
            df.index = df.index + 1
    print('Data saved to : %s'%file_to_save)        
    df.to_csv(file_to_save)

# If the data is already there, just load it from the CSV
else:
    print('File already exists. Loading data from CSV')
    df = pd.read_csv(file_to_save)

# Sort DataFrame by date
df = df.sort_values('Date')

# normalize data
cols = [2,3,4,5,6,7]
df_subset = df[df.columns[cols]]
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(df_subset)
df_normalized = pd.DataFrame(np_scaled)


'''
df_date = pd.DataFrame(df['Date'])
df_rest = pd.DataFrame(np_scaled)
df_normalized = df_date.join(df_rest)
print(df_normalized)
'''

# Setting X and Y for training and testing
window = 5
X_train, y_train, X_test, y_test = load_data(df_normalized[::-1], window)
print("X_train", X_train.shape)
print("y_train", y_train.shape)
print("X_test", X_test.shape)
print("y_test", y_test.shape)

# Loading the model sequence structure
model = build_model([6,window,1])

# Executing the model
# Use the training set to train the model
model.fit(
    X_train,
    y_train,
    batch_size=512,
    epochs=20,
    validation_split=0.1,
    verbose=1)

# Calculate RMS/RMSE results
trainScore = model.evaluate(X_train, y_train, verbose=0)
print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))

testScore = model.evaluate(X_test, y_test, verbose=0)
print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))

# make a prediction
# creates states
predictions = model.predict(X_test)
model.save('Trained Stock Model/'+'stock_predictor.h5')

# Plot the predictions!
plt.plot(predictions ,color='red', label='Predicted Values')
plt.plot(y_test,color='blue', label='Actual Test Values')
plt.legend(loc='upper left')
plt.show()

'''
# create a loop where you start with the last step of the previous prediction
future = []
#last step from the previous prediction
currentStep = predictions[:,-1:,:] 

for i in range(30):
    currentStep = model.predict(currentStep) #get the next step
    future.append(currentStep) #store the future steps    

print(future)
#after processing a sequence, reset the states for safety
model.reset_states()
'''